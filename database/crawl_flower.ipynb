{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dữ liệu đã được ghi vào tệp CSV: links.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "\n",
    "# Tạo một tệp CSV để lưu các liên kết\n",
    "csv_filename = \"links.csv\"\n",
    "\n",
    "# Mở tệp CSV để ghi dữ liệu\n",
    "with open(csv_filename, 'w', newline='') as csvfile:\n",
    "    csv_writer = csv.writer(csvfile)\n",
    "    csv_writer.writerow([\"URL\"])  # Ghi tiêu đề của cột\n",
    "\n",
    "    # URL của trang bạn muốn cào\n",
    "    url = \"https://www.serenataflowers.com/all-flowers\"\n",
    "\n",
    "    # Lấy nội dung của trang web\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "    # Tìm tất cả các thẻ <meta> có thuộc tính itemprop=\"url\"\n",
    "    meta_tags = soup.find_all(\"meta\", itemprop=\"url\")\n",
    "\n",
    "    # Lặp qua các thẻ <meta> và lấy giá trị của thuộc tính \"content\"\n",
    "    for meta_tag in meta_tags:\n",
    "        url = meta_tag.get(\"content\")\n",
    "        csv_writer.writerow([url])\n",
    "\n",
    "print(\"Dữ liệu đã được ghi vào tệp CSV: \" + csv_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Tạo một danh sách để lưu thông tin sản phẩm\n",
    "products = []\n",
    "\n",
    "# Đọc tệp CSV và lấy danh sách các liên kết\n",
    "df = pd.read_csv('links.csv')\n",
    "links = df['URL']\n",
    "\n",
    "# Lặp qua từng liên kết\n",
    "for link in links:\n",
    "    # Tải nội dung của liên kết\n",
    "    response = requests.get(link)\n",
    "    if response.status_code == 200:\n",
    "        page_content = response.text\n",
    "\n",
    "        soup = BeautifulSoup(page_content, 'html.parser')\n",
    "\n",
    "        # Tạo một từ điển để lưu thông tin sản phẩm hiện tại\n",
    "        product = {}\n",
    "\n",
    "        # name\n",
    "        product['name'] = soup.find('h1', itemprop='name', class_='product-page-title').text\n",
    "\n",
    "        description_element = soup.find('p', itemprop='description')\n",
    "\n",
    "        # original price\n",
    "        original_price_element = soup.find('span', class_='compare-price hide-for-small-only')\n",
    "\n",
    "        if original_price_element is not None:\n",
    "            product['original_price'] = original_price_element.text\n",
    "\n",
    "        # price\n",
    "        product['price'] = soup.find('span', class_='price hide-for-small-only').text\n",
    "\n",
    "        description_element = soup.find('p', itemprop='description')\n",
    "\n",
    "        # description\n",
    "        if description_element is not None:\n",
    "            product['description'] = description_element.get_text()\n",
    "\n",
    "        # details\n",
    "        ul_element = soup.find('ul', class_='tick-list')\n",
    "\n",
    "        if ul_element is not None:\n",
    "            list_items = ul_element.find_all('li')\n",
    "            details = [item.get_text().strip() for item in list_items]\n",
    "            product['details'] = details\n",
    "\n",
    "        # delivery\n",
    "        tab3 = soup.find('div', class_='panel', id='tab-3-panel')\n",
    "\n",
    "        if tab3 is not None:\n",
    "            product['delivery'] = tab3.get_text()\n",
    "\n",
    "        # sub info\n",
    "        tab4 = soup.find('div', class_='panel', id='tab-4-panel')\n",
    "\n",
    "        if tab4 is not None:\n",
    "            product['sub_info'] = tab4.get_text()\n",
    "\n",
    "        # link image\n",
    "        target_element = soup.find(class_='grid-x subscription-tiles product-thumbs')\n",
    "        hrefs = [a['href'] for a in target_element.find_all('a') if 'href' in a.attrs][:5]  # Lấy chỉ 5 liên kết\n",
    "        product['images'] = hrefs\n",
    "\n",
    "        # Overall Rating\n",
    "        rate_element = soup.find('span', class_='review-total')\n",
    "\n",
    "        if rate_element is not None:\n",
    "            product['overall_rating'] = rate_element.get_text()\n",
    "\n",
    "        # Reviews\n",
    "        reviews = []\n",
    "        review_elements = soup.find_all('div', class_='cell testimonial medium-6')\n",
    "\n",
    "        for review in review_elements:\n",
    "            rate = review.get('reviewrating')\n",
    "\n",
    "            if rate is not None:\n",
    "                review_info = {}\n",
    "                review_info['rate'] = rate\n",
    "\n",
    "                content_element = review.find('meta', itemprop='reviewBody')\n",
    "\n",
    "                if content_element is not None:\n",
    "                    review_info['content'] = content_element.get('content')\n",
    "\n",
    "                name_element = review.find('span', itemprop='author')\n",
    "                name = name_element.get_text() if name_element else None\n",
    "                review_info['name'] = name\n",
    "\n",
    "                date_element = review.find('time', itemprop='dateCreated')\n",
    "                date = date_element.get_text() if date_element else None\n",
    "                review_info['date'] = date\n",
    "\n",
    "                reviews.append(review_info)\n",
    "\n",
    "        product['reviews'] = reviews\n",
    "\n",
    "        # Thêm sản phẩm vào danh sách sản phẩm\n",
    "        products.append(product)\n",
    "\n",
    "# Lưu danh sách sản phẩm vào tệp JSON\n",
    "with open('products.json', 'w') as json_file:\n",
    "    json.dump(products, json_file, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\dangt\\OneDrive\\Máy tính\\flower_shop\\database\\crawl_flower.ipynb Cell 3\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dangt/OneDrive/M%C3%A1y%20t%C3%ADnh/flower_shop/database/crawl_flower.ipynb#W2sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m soup \u001b[39m=\u001b[39m BeautifulSoup(page_content, \u001b[39m'\u001b[39m\u001b[39mhtml.parser\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dangt/OneDrive/M%C3%A1y%20t%C3%ADnh/flower_shop/database/crawl_flower.ipynb#W2sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m \u001b[39m# Tìm tên loại hoa trong tiêu đề trang\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/dangt/OneDrive/M%C3%A1y%20t%C3%ADnh/flower_shop/database/crawl_flower.ipynb#W2sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m category_title \u001b[39m=\u001b[39m soup\u001b[39m.\u001b[39;49mfind(\u001b[39m'\u001b[39;49m\u001b[39mh1\u001b[39;49m\u001b[39m'\u001b[39;49m, class_\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mpage-title\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m.\u001b[39;49mtext\u001b[39m.\u001b[39mstrip()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dangt/OneDrive/M%C3%A1y%20t%C3%ADnh/flower_shop/database/crawl_flower.ipynb#W2sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m \u001b[39m# Lưu tên loại hoa vào danh sách categories\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dangt/OneDrive/M%C3%A1y%20t%C3%ADnh/flower_shop/database/crawl_flower.ipynb#W2sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m categories_list[category] \u001b[39m=\u001b[39m category_title\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Danh sách các từ khóa cho các loại hoa\n",
    "flower_categories = [\n",
    "    \"Birthday\",\n",
    "    \"Romantic\",\n",
    "    \"Sympathy\",\n",
    "    \"Anniversary\",\n",
    "    \"Get Well\",\n",
    "    \"Baby\",\n",
    "    \"Thank%20you\",\n",
    "    \"Thinking%20of%20you\",\n",
    "    \"Congratulations\",\n",
    "]\n",
    "\n",
    "categories_list = {}\n",
    "\n",
    "# Duyệt qua từng từ khóa và tạo và duyệt liên kết\n",
    "for category in flower_categories:\n",
    "    # Tạo liên kết dựa trên từ khóa\n",
    "    url = f'https://www.serenataflowers.com/{category.lower()}-flowers'\n",
    "\n",
    "    # Tải nội dung trang web\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Kiểm tra xem trang đã được tải thành công không\n",
    "    if response.status_code == 200:\n",
    "        page_content = response.text\n",
    "\n",
    "        # Sử dụng BeautifulSoup để phân tích nội dung HTML\n",
    "        soup = BeautifulSoup(page_content, 'html.parser')\n",
    "\n",
    "        # Tạo danh sách rỗng cho từng loại hoa\n",
    "        categories_list[category] = []\n",
    "\n",
    "        # Tìm tất cả các tên sản phẩm từ trang hiện tại và thêm vào danh sách\n",
    "        product_titles = soup.find_all('span', class_='container-flex product-title')\n",
    "        product_names = [title.get_text().strip() for title in product_titles]\n",
    "\n",
    "        categories_list[category] = product_names\n",
    "\n",
    "        print(f\"Loại hoa: {category}\")\n",
    "        print(\"Danh sách sản phẩm:\")\n",
    "        for name in product_names:\n",
    "            print(name)\n",
    "        print(\"\\n\")\n",
    "    else:\n",
    "        print(f\"Lỗi khi tải trang web cho loại hoa: {category}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
